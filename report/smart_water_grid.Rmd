---
title: "Correlating water quality fluctuations with sensor data"
subtitle: "Vitens Open Data Challenge: Smart Water Grid"
author: "Dennis van den Berg"
date: "24/01/2016"
output: html_document
---


## Introduction

Central question: What are the correlations between changes in water quality measued by Eventlab sensors and other real-time measurements, statuses and alarm values?

See documentation: https://github.com/dljvandenberg/smart_water_grid/blob/master/doc/Vitens%20Data%20Challenge%2007122015.pdf


## Data Description

```{r, message=FALSE, echo=FALSE}
library(dplyr)
library(reshape2)
library(lubridate)
library(ggplot2)
library(caret)
library(Rmisc)
library(gplots)

dir.data <- "~/git/smart_water_grid/data"
setwd(dir.data)

createvariablefromfilename <- function(filename) {
    # Chop off beginning and end of filename and convert to valid variable name
    variablename <- make.names(gsub("(^Dump_|.csv$)", "", filename))
}

readfile <- function(file) {
    variablename <- createvariablefromfilename(file)
    
    data <- read.csv(file, comment.char = "#", col.names = c("Time", variablename), colClasses = c("character", "numeric"),
                     na.strings = c("", " ", "CalcFailed", "Calc Failed", "Bad", "BadInput", "Bad Input", "PtCreated", "Pt Created", "CommFail", "ScanOff", "Configure", "I/OTimeout"))
    
    # Convert to POSIXct/POSIXt time format
    data$Time <- ymd_hms(data$Time)
    
    return(data)
}

readfiles <- function(fileslist) {
    listofdataframes <- lapply(fileslist, function(file) readfile(file))
    merged <- Reduce(function(x, y) merge(x, y, all=TRUE), listofdataframes)

    return(merged)
}

selecttimerange <- function(dataframe, begintime = -Inf, endtime = Inf) {
    subset(dataframe, Time >= begintime & Time <= endtime)
}

heatmap.abovethreshold <- function(eventlab.dataframe, threshold=1) {
    # Drop first column (Time), convert to 1 if above threshold and 0 if not, convert to matrix
    eventlab.alarms <- as.matrix(1 * (eventlab.dataframe[, -1] > threshold))
    
    # Draw heatmap
    heatmap.2(eventlab.alarms, Rowv=NA, Colv=NA, col = c('Green', 'Red'), na.color='Grey', scale="column", trace="none", margins=c(5,0))
}
```


### Data files

```{r, echo=FALSE}
files.all <- list.files(path=dir.data, pattern="csv$")
```

Our data set contains `r length(files.all)` files and its total size is a little over 5 GB. All files are in .csv format and contain Timestamp-Value pairs. Furthermore the data files contain some additional information in the header comments. 

The file name contains the variable that was measured, in format `Dump_<variable>.csv`:

```{r, echo=FALSE}
head(files.all, n=4)
```



### Time range

According to the documentation measurements are done in the time range January 2014 to December 2015. We confirmed this by looking at the data. We also observe that some variables are only available in specific time ranges, often data is missing in large blocks of this 2-year time range.

```{r, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
setwd(dir.data)
files.select <- list.files(path=dir.data, pattern="vitnor.*csv$")[1]
data.select <- readfiles(files.select)
summary(data.select)
ggplot(data.select, aes_string(x="Time", y=names(data.select)[2])) + geom_point() + ggtitle("Raw data (unaggregated)")
```

In general the frequency of data logging is 1 measurement per minute.


### Variable overview

In the documentation we see the following explanation of variable names:

Quantity      | Variable code    | Remarks
------------- | -------------    | -------------
Eventlab data | `*vitnor*`       | 3 per sensor (`vitnor1`, `vitnor2`, `vitnor3`). Alarm codes are given in case 1 or more values above threshold (code Orange for `1 > max(vitnor*) >= 1.5`, code Red for `max(vitnor*) > 1.5`)
Temperature   | `*TM*`           | 
Flow          | `*FT*`, `*VO*`   | Negative values allowed (in case of opposite flow direction)
Pressure      | `*PT*`, `*DO*`   | We found that these had to be followed by 2 digits (`*PTxx*`, `*DOxx*`) in order not to select incorrect variables 
Conductivity  | `FR-PNB_TR00QI03PV*`, `FR-POH_-TR00QI03PV*` | 
Acidity (pH)  | `FR-PNB_TR00QI01PV*`, `FR-POH_-TR00QI02PV*`, `FR-PSP-TR00QI01*`, `FR-PTW_TR01QI01PV*` | 
Turbidity     | `FR-PTW_TR01QI02PV*`, `FR-PSP-TR00QI02*`, `FR-PNB_TR00QI02PV*`, `FR-POH_-TR00QI01PV*` | 
Other         | (None of the above) | Status values of pumps, reservoirs, valves, etc

```{r, echo=FALSE}
files.vitnor <- list.files(path=dir.data, pattern="vitnor.*csv")
files.temperature <- list.files(path=dir.data, pattern="TM.*csv$")
files.flow <- list.files(path=dir.data, pattern="(FT|VO).*csv$")
files.pressure <- list.files(path=dir.data, pattern="(PT|DO)[0123456789][0123456789].*csv$")
files.conductivity <- list.files(path=dir.data, pattern="(FR-PNB_TR00QI03PV|FR-POH_-TR00QI03PV).*csv$")
files.acidity <- list.files(path=dir.data, pattern="(FR-PNB_TR00QI01PV|FR-POH_-TR00QI02PV|FR-PSP-TR00QI01|FR-PTW_TR01QI01PV).*csv$")
files.turbidity <- list.files(path=dir.data, pattern="(FR-PTW_TR01QI02PV|FR-PSP-TR00QI02|FR-PNB_TR00QI02PV|FR-POH_-TR00QI01PV).*csv$")
files.other <- Reduce(setdiff, list(files.all, files.vitnor, files.temperature, files.flow, files.pressure, files.conductivity, files.acidity, files.turbidity))
```


### Predictor and response variables

We are interested in Eventlab measurements (variable names `*vitnor*`) as **response variables**

* There are `r length(files.vitnor)` variables for Eventlab measurements
* These represent `r length(files.vitnor)/3` Eventlab sensors, each of which produce a set of three variables (`*vitnor1*`, `*vitnor2*` and `*vitnor3*`)
* Specifically, we are interested in events with values above a threshold for these variables (>1).

That leaves `r length(files.all)-length(files.vitnor)` variables that we can use as **potential predictors**:

* `r length(files.temperature)` for temperature
* `r length(files.flow)` for flow
* `r length(files.pressure)` for pressure
* `r length(files.conductivity)` for conductivity
* `r length(files.acidity)` for acidity
* `r length(files.turbidity)` for turbidity
* `r length(files.other)` other

The data quality of these variables varies. Some files do not even contain any data points.



## Exploratory Analysis

### Selection of Data Subset

```{r, echo=FALSE}
pattern.response="FR-MOBMS-vitnor1-meetwaarde"
time.begin.1=ymd("2015-06-25")
time.end.1=ymd("2015-07-05")
time.begin.2=ymd_hms("2015-06-29T00:00:00")
time.end.2=ymd_hms("2015-06-29T12:00:00")
time.begin.3=ymd_hms("2015-06-29T02:00:00")
time.end.3=ymd_hms("2015-06-29T03:00:00")
threshold.orange=1
threshold.red=1.5
files.response <- list.files(path=dir.data, pattern=pattern.response)
vars.response <- createvariablefromfilename(files.response)
```

Based on large blocks of consecutive data seen in exploratory plots and multiple peaks of Eventlab variables exceeding the threshold we decided to focus on the `r vars.response` variable as response variable.

Zooming in on a specific Eventlab alarm event starting around `r time.begin.3` we observe that the vitnor values can rise and exceed the threshold (>1 resp >1.5) abruptly in a matter of minutes and that this process can repeat itself within hours:

```{r, echo=FALSE}
setwd(dir.data)
data.response <- readfiles(files.response)
data.response.1 <- selecttimerange(data.response, time.begin.1, time.end.1)
data.response.2 <- selecttimerange(data.response, time.begin.2, time.end.2)
data.response.3 <- selecttimerange(data.response, time.begin.3, time.end.3)
plot.response.1 <- ggplot(data.response.1, aes_string(x="Time", y=names(data.response)[2])) + geom_point() + ggtitle("Eventlab - day timescale") + geom_hline(yintercept=threshold.orange, color="orange") + geom_hline(yintercept=threshold.red, color="red")
plot.response.2 <- ggplot(data.response.2, aes_string(x="Time", y=names(data.response)[2])) + geom_point() + ggtitle("Eventlab - hour timescale") + geom_hline(yintercept=threshold.orange, color="orange") + geom_hline(yintercept=threshold.red, color="red")
plot.response.3 <- ggplot(data.response.3, aes_string(x="Time", y=names(data.response)[2])) + geom_point() + ggtitle("Eventlab - minute timescale") + geom_hline(yintercept=threshold.orange, color="orange") + geom_hline(yintercept=threshold.red, color="red")
plot.response.1
plot.response.2
plot.response.3
```


### Heatmaps of Eventlab alarm events

```{r, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
# Select subset of vitnor variables, read data for specific time range and plot heatmap
setwd(dir.data)
pattern.eventlab="FR-MOBMS-vitnor"
files.eventlab <- list.files(path=dir.data, pattern=pattern.eventlab)
data.eventlab <- readfiles(files.eventlab)
time.begin=ymd_hms("2015-05-20T00:00:00")
time.end=ymd_hms("2015-06-30T00:00:00")
data.eventlab.timerange <- selecttimerange(data.eventlab, time.begin, time.end)
heatmap.abovethreshold(data.eventlab.timerange, threshold=1)
```


### Correlations



## Follow-up Actions

Mention that Eventlab peaks justify hourly aggregations (mean, max, ..). Also causes less NAs, less peak events, smaller data set, easier finding signals with small time lag


Data import & aggregation:

1. Select time range during import (instead of after)
1. Aggregate using hourly variance (to see fluctuations/deltas)
1. Aggregate above threshold TRUE/FALSE (apply to Eventlab data)


Summarizations & visualizations:

1. Multivariate plots
1. Optional tables, boxplots
1. Pair plots
1. Heatmaps (al least for eventlab, possibly for other categories)
1. Dendrogram (related vars within categories)


Machine Learning & Predictions:

1. Select 1 response var
1. Select 1 interesting dataset with predictors (for example turbidity)
1. Select interesting time range (maybe not necessary)
1. Merge predictor set and response var
1. Remove rows with NA (consider these as clean datasets that we can work with)
1. Split into train and test sets
1. Apply ML algorithm (RF, GBM, Tree)
1. Predict and validate
1. Check list of important predictors



## Data Source

Raw data was provided by Vitens.